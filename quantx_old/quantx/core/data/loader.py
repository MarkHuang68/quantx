# quantx/core/data/loader.py
# æª”æ¡ˆ: quantx/core/data/loader.py
# ç‰ˆæœ¬: v5 (æœ€çµ‚ä¿®å¾©ï¼šInterfaceError)
# èªªæ˜:
# - ä¿®æ­£äº†æ™‚é–“æˆ³å–®ä½è¢«é‡è¤‡è½‰æ›çš„éŒ¯èª¤ã€‚
# - æ–°å¢äº†å° inf å€¼çš„è™•ç†ï¼Œå°‡å…¶æ›¿æ›ç‚º NaN ä»¥ä¾¿èƒ½è¢« dropna æ¸…é™¤ã€‚

import sqlite3
import threading
import pandas as pd
import numpy as np # å¼•å…¥ numpy ç”¨æ–¼è™•ç† inf
from pathlib import Path
from quantx.core.timeframe import parse_tf_seconds

class DataLoader:
    def _normalize_symbol(self, symbol: str) -> str:
        """å°‡å„ç¨®æ ¼å¼çš„ symbol (ä¾‹å¦‚ 'BTC/USDT:USDT', 'BTC/USDT') æ¨™æº–åŒ–ç‚º 'BTCUSDT'ã€‚"""
        return symbol.replace('/', '').split(':')[0]

    def __init__(self, cache_dir: str, scope: str, provider):
        self.cache_dir = Path(cache_dir)
        self.scope = scope
        self.provider = provider
        self.db_path = self.cache_dir / scope / "data.db"
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.lock = threading.Lock() # åˆå§‹åŒ–ç·šç¨‹é–
        self._init_schema()

    def _init_schema(self):
        q = """
        CREATE TABLE IF NOT EXISTS ohlcv (
            symbol TEXT, ts INTEGER, open REAL, high REAL, low REAL,
            close REAL, volume REAL, PRIMARY KEY(symbol, ts)
        )
        """
        self.conn.execute(q)
        self.conn.commit()

    def save(self, symbol: str, df: pd.DataFrame):
        # [æ ¸å¿ƒä¿®æ­£] ä½¿ç”¨é–ä¾†ä¿è­·æ•´å€‹ä¿å­˜éç¨‹ï¼Œé˜²æ­¢ä¸¦ç™¼å¯«å…¥è¡çª
        with self.lock:
            if df.empty: return

            normalized_symbol = self._normalize_symbol(symbol)
            df = df.copy()

            # --- [æ™‚é–“æˆ³è™•ç†] ---
            if isinstance(df.index, pd.DatetimeIndex):
                df["ts"] = (df.index.astype('int64') // 10**9).astype(int)
            elif "timestamp" in df.columns:
                df["ts"] = df["timestamp"].astype(int)
            else:
                raise ValueError("DataFrame ç¼ºå°‘å¯ç”¨çš„æ™‚é–“æˆ³ä¾†æº (DatetimeIndex æˆ– 'timestamp' æ¬„ä½)")

            df["symbol"] = normalized_symbol
            cols_to_save = ["symbol", "ts", "open", "high", "low", "close", "volume"]

            if not all(c in df.columns for c in cols_to_save):
                raise ValueError("DataFrame ç¼ºå°‘å¿…è¦çš„ OHLCV æˆ– ts æ¬„ä½")

            df_to_save = df[cols_to_save]

            # --- [å¥å£¯æ€§å¼·åŒ–] ---
            df_to_save = df_to_save.replace([np.inf, -np.inf], np.nan)

            for col in ["open", "high", "low", "close", "volume"]:
                df_to_save[col] = pd.to_numeric(df_to_save[col], errors='coerce')

            df_to_save = df_to_save.dropna()

            if df_to_save.empty:
                return

            df_to_save = df_to_save.astype({
                "symbol": str, "ts": int, "open": float, "high": float,
                "low": float, "close": float, "volume": float
            })

            try:
                self.conn.executemany(
                    "INSERT OR REPLACE INTO ohlcv (symbol, ts, open, high, low, close, volume) VALUES (?, ?, ?, ?, ?, ?, ?)",
                    df_to_save.values.tolist()
                )
                self.conn.commit()
            except Exception as e:
                self.log.error(f"åœ¨ä¿å­˜ {normalized_symbol} åˆ°æ•¸æ“šåº«æ™‚å‡ºéŒ¯: {e}")
                # å³ä½¿å‡ºéŒ¯ï¼Œä¹Ÿè¦ç¢ºä¿ä¸æœƒå½±éŸ¿å…¶ä»–ç·šç¨‹ï¼Œæ‰€ä»¥é€™è£¡ä¸æ‹‹å‡ºç•°å¸¸ï¼Œåªè¨˜éŒ„æ—¥èªŒ

    def read(self, symbol: str, start_ts: int, end_ts: int) -> pd.DataFrame:
        normalized_symbol = self._normalize_symbol(symbol)
        q = "SELECT ts, open, high, low, close, volume FROM ohlcv WHERE symbol=? AND ts BETWEEN ? AND ? ORDER BY ts"
        df = pd.read_sql(q, self.conn, params=(normalized_symbol, start_ts, end_ts))
        if df.empty: return df

        # å°‡ ts è½‰æ›ç‚º DatetimeIndex
        df['timestamp'] = pd.to_datetime(df['ts'], unit='s', utc=True)
        df = df.set_index('timestamp')
        return df

    def load_ohlcv(self, symbol: str, tf: str, start, end) -> pd.DataFrame:
        if isinstance(start, str): start = pd.to_datetime(start, utc=True)
        if isinstance(end, str): end = pd.to_datetime(end, utc=True)

        start_ts = int(start.timestamp())
        end_ts = int(end.timestamp())

        # è®€å– 1m æ•¸æ“š (read æ–¹æ³•ç¾åœ¨æœƒå›å‚³å¸¶æœ‰ DatetimeIndex çš„ df)
        df_1m = self.read(symbol, start_ts, end_ts)

        # æª¢æŸ¥æ˜¯å¦éœ€è¦å¾é ç«¯ provider è£œæŠ“æ•¸æ“š
        need_fetch = df_1m.empty
        if not df_1m.empty:
            min_ts_in_db = df_1m.index.min().timestamp()
            max_ts_in_db = df_1m.index.max().timestamp()
            # éœ€è¦è£œé ­æˆ–è£œå°¾
            diff = parse_tf_seconds(tf)
            if min_ts_in_db - diff > start_ts or max_ts_in_db + diff < end_ts:
                need_fetch = True
        
        if need_fetch:
            # é€™è£¡ä¿®æ­£ç‚ºå‚³å…¥ '1m' ä½œç‚º Provider çš„è«‹æ±‚æ™‚é–“æ¡†
            raw_df_from_provider = self.provider.fetch_klines(symbol, start, end, tf='1m')
            
            # ğŸŸ¢ ä¿®æ­£ï¼šåˆªé™¤èˆŠçš„ã€éŒ¯èª¤çš„ 'timestamp' è™•ç†é‚è¼¯
            # if not raw_df_from_provider.empty:
            #     raw_df_from_provider["ts"] = raw_df_from_provider["timestamp"].astype(int) # <-- é€™æ˜¯å°è‡´ KeyError çš„èˆŠé‚è¼¯
            
            if not raw_df_from_provider.empty:
                self.save(symbol, raw_df_from_provider)
            # é‡æ–°å¾è³‡æ–™åº«è®€å–å®Œæ•´çš„ 1m æ•¸æ“š
            df_1m = self.read(symbol, start_ts, end_ts)

        if tf == "1m":
            return df_1m

        # èšåˆæˆç›®æ¨™æ™‚é–“é€±æœŸ
        return self.aggregate_from_1m(df_1m, tf)

    def aggregate_from_1m(self, df: pd.DataFrame, dst_tf: str) -> pd.DataFrame:
        if df.empty: return df

        # df å‚³å…¥æ™‚å·²ç¶“æœ‰ DatetimeIndex
        if dst_tf.endswith("m"): rule = f"{int(dst_tf[:-1])}min"
        elif dst_tf.endswith("h"): rule = f"{int(dst_tf[:-1])}h"
        elif dst_tf.endswith("d"): rule = f"{int(dst_tf[:-1])}d"
        else: raise ValueError(f"ä¸æ”¯æ´çš„æ™‚é–“é€±æœŸ: {dst_tf}")

        agg = df.resample(rule).agg({
            "open": "first", "high": "max", "low": "min",
            "close": "last", "volume": "sum"
        }).dropna()
        
        # å›å‚³çš„ DataFrame ä¿æŒ DatetimeIndex
        return agg