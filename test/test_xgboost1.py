import ccxt
import pandas as pd
import talib
import xgboost as xgb
# --- æ–°å¢: åŒ¯å…¥åˆ†é¡è©•ä¼°å·¥å…· ---
from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay
# -----------------------------
import numpy as np
import warnings
import matplotlib.pyplot as plt
import time

# --- æ–°å¢: åŒ¯å…¥èª¿æ ¡å·¥å…· ---
from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit
from scipy.stats import uniform, randint
# --------------------------

# å¿½ç•¥ pandas çš„æœªä¾†è­¦å‘Š
warnings.simplefilter(action='ignore', category=FutureWarning)

# --- æ­¥é©Ÿ 1: ä½¿ç”¨ CCXT ç²å–è³‡æ–™ ---
# (èˆ‡ä¸Šä¸€ç‰ˆç›¸åŒï¼Œä¿æŒä¸è®Š)
def fetch_data(symbol='BTC/USDT', timeframe='5m', total_limit=10000):
    """
    å¾å¹£å®‰ (Binance) ç²å–å¤§é‡ OHLCV è³‡æ–™ (ä½¿ç”¨è¿´åœˆ)ã€‚
    """
    print(f"--- æ­¥é©Ÿ 1: æ­£åœ¨å¾ Binance ç²å– {symbol} {timeframe} è³‡æ–™ (ç›®æ¨™ {total_limit} ç­†) ---")
    
    exchange = ccxt.binance({'rateLimit': 1200, 'enableRateLimit': True})
    
    try:
        timeframe_duration_ms = exchange.parse_timeframe(timeframe) * 1000
    except Exception as e:
        print(f"Timeframe æ ¼å¼éŒ¯èª¤: {e}ã€‚")
        return None
        
    limit_per_request = 1000
    all_ohlcv = []
    total_duration_ms = total_limit * timeframe_duration_ms
    since_timestamp = exchange.milliseconds() - total_duration_ms
    
    print(f"å°‡å¾ {pd.to_datetime(since_timestamp, unit='ms')} (å¤§ç´„) é–‹å§‹ç²å–è³‡æ–™...")

    while True:
        try:
            ohlcv = exchange.fetch_ohlcv(symbol, timeframe, since=since_timestamp, limit=limit_per_request)
            if not ohlcv:
                print("ç²å–å®Œæˆ (å·²é”æœ€æ–°è³‡æ–™)ã€‚")
                break
            all_ohlcv.extend(ohlcv)
            last_timestamp = ohlcv[-1][0]
            since_timestamp = last_timestamp + timeframe_duration_ms
            print(f"å·²ç²å– {len(all_ohlcv)} ç­†è³‡æ–™...")
        except ccxt.NetworkError as e:
            print(f"ç¶²è·¯éŒ¯èª¤: {e}ï¼Œ5 ç§’å¾Œé‡è©¦...")
            time.sleep(5)
        except Exception as e:
            print(f"ç²å–è³‡æ–™æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}")
            return None

    print(f"--- è³‡æ–™ç²å–å®Œç•¢ï¼Œç¸½å…± {len(all_ohlcv)} ç­† ---")

    if not all_ohlcv:
        print("æœ€çµ‚æœªç²å–åˆ°ä»»ä½•è³‡æ–™ã€‚")
        return None
        
    df = pd.DataFrame(all_ohlcv, columns=[
        'timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'
    ])
    df = df.drop_duplicates(subset=['timestamp'])
    
    if len(df) > total_limit:
        df = df.tail(total_limit)
    elif len(df) < total_limit:
        print(f"è­¦å‘Šï¼šäº¤æ˜“æ‰€æä¾›çš„è³‡æ–™ä¸è¶³ {total_limit} ç­†ï¼Œåƒ…æœ‰ {len(df)} ç­†ã€‚")
        
    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
    df.set_index('timestamp', inplace=True)
    
    for col in ['Open', 'High', 'Low', 'Close', 'Volume']:
        df[col] = pd.to_numeric(df[col], errors='coerce')
        
    print("DataFrame è™•ç†å®Œæˆã€‚")
    return df

# --- æ­¥é©Ÿ 2: ä½¿ç”¨ TA-Lib é€²è¡Œç‰¹å¾µå·¥ç¨‹ ---
# (èˆ‡ä¸Šä¸€ç‰ˆç›¸åŒï¼Œä¿æŒä¸è®Š)
def create_features(df):
    """
    è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ä½œç‚ºç‰¹å¾µã€‚
    """
    if df is None:
        return None
        
    print("\n--- æ­¥é©Ÿ 2: æ­£åœ¨è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ (ç‰¹å¾µå·¥ç¨‹) ---")
    
    close_prices = df['Close'].values.astype(float)
    high_prices = df['High'].values.astype(float)
    low_prices = df['Low'].values.astype(float)
    volume = df['Volume'].values.astype(float)

    try:
        # æ‚¨çš„ 5m æ¥µé€ŸæŒ‡æ¨™
        df['RSI'] = talib.RSI(close_prices, timeperiod=5)
        # df['WMA_close_2'] = talib.WMA(close_prices, timeperiod=2)
        # df['WMA_high_2'] = talib.WMA(high_prices, timeperiod=2)
        # df['WMA_low_2'] = talib.WMA(low_prices, timeperiod=2)
        macd, macdsignal, _ = talib.MACD(close_prices, fastperiod=6, slowperiod=13, signalperiod=9)
        df['MACD'] = macd
        df['MACD_signal'] = macdsignal
        df['ADX'] = talib.ADX(df['High'], df['Low'], df['Close'], timeperiod=5)
        df['ADX_hist'] = talib.PLUS_DI(df['High'], df['Low'], df['Close'], timeperiod=5) - talib.MINUS_DI(df['High'], df['Low'], df['Close'],timeperiod=5)
        df['OBV'] = talib.OBV(close_prices, volume)
        upperband, middleband, lowerband = talib.BBANDS(close_prices, timeperiod=2, nbdevup=2, nbdevdn=2, matype=0)
        df['BB_Width'] = (upperband - lowerband) / (middleband + 1e-10)
        # df['BB_Percent'] = (close_prices - lowerband) / (upperband - lowerband + 1e-10)
        df['MOM'] = talib.MOM(close_prices, timeperiod=5)
        # --------------------------------
        
        original_len = len(df)
        df_features = df.dropna() 
        print(f"å·²å»é™¤ {original_len - len(df_features)} ç­†èˆŠè³‡æ–™ (å› è¨ˆç®—æŒ‡æ¨™ç”¢ç”Ÿ NaN)ã€‚")
        
        return df_features

    except Exception as e:
        print(f"è¨ˆç®—ç‰¹å¾æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

# --- æ­¥é©Ÿ 3 & 4: (***é‡å¤§æ›´æ–°: æ”¹ç‚ºåˆ†é¡æ¨¡å‹***) ---

def train_and_predict(df_features):
    """
    æº–å‚™è³‡æ–™ã€è‡ªå‹•èª¿æ ¡ä¸¦è¨“ç·´ XGBoost åˆ†é¡æ¨¡å‹ã€‚
    """
    if df_features is None or df_features.empty:
        print("æ²’æœ‰è¶³å¤ çš„ç‰¹å¾µè³‡æ–™é€²è¡Œè¨“ç·´ã€‚")
        return

    print("\n--- æ­¥é©Ÿ 3: æº–å‚™è³‡æ–™ (åˆ†é¡) ---")

    features = [
        'RSI',
        # 'WMA_close_2', 'WMA_high_2', 'WMA_low_2',
        'MACD', 'MACD_signal', 'OBV',
        'ADX', 'ADX_hist',
        'Volume',
        'BB_Width',
        # 'BB_Percent',
        'MOM'
    ]
    
    df_model = df_features.copy()
    
    # --- ä¿®æ”¹: å»ºç«‹åˆ†é¡ç›®æ¨™ (target) ---
    # é æ¸¬ä¸‹ä¸€æ ¹ K æ£’æ˜¯æ¼² (1) é‚„æ˜¯è·Œ (0)
    df_model['target'] = (df_model['Close'].shift(-1) > df_model['Close']).astype(int)
    # ----------------------------------
    
    df_model = df_model.dropna()

    X = df_model[features]
    y = df_model['target']

    test_size = 0.2 
    split_index = int(len(X) * (1 - test_size))

    X_train, X_test = X[:split_index], X[split_index:]
    y_train, y_test = y[:split_index], y[split_index:]

    print(f"è¨“ç·´é›†ç­†æ•¸: {len(X_train)}, æ¸¬è©¦é›†ç­†æ•¸: {len(X_test)}")
    print(f"è¨“ç·´é›†ä¸­ 'æ¼² (1)' çš„æ¯”ä¾‹: {y_train.mean():.2%}")
    print(f"æ¸¬è©¦é›†ä¸­ 'æ¼² (1)' çš„æ¯”ä¾‹: {y_test.mean():.2%}")

    # --- æ­¥é©Ÿ 3a: è¶…åƒæ•¸èª¿æ ¡è¨­å®š (åˆ†é¡) ---
    
    param_dist = {
        'n_estimators': randint(500, 1500),
        'learning_rate': uniform(0.01, 0.05),
        'max_depth': randint(3, 8),
        'subsample': uniform(0.7, 0.3),
        'colsample_bytree': uniform(0.7, 0.3)
    }

    # --- ä¿®æ”¹: æ›´æ›ç‚º XGBClassifier ---
    xgb_clf_base = xgb.XGBClassifier(
        objective='binary:logistic', # <-- ä¿®æ”¹
        eval_metric='logloss',       # <-- ä¿®æ”¹
        n_jobs=-1,
        random_state=42
    )
    # ---------------------------------

    tscv = TimeSeriesSplit(n_splits=3)

    # --- ä¿®æ”¹: è©•åˆ†æ¨™æº–æ”¹ç‚º 'accuracy' ---
    random_search = RandomizedSearchCV(
        estimator=xgb_clf_base,
        param_distributions=param_dist,
        n_iter=25,
        cv=tscv,
        scoring='accuracy', # <-- ä¿®æ”¹
        n_jobs=-1,
        verbose=2,
        random_state=42
    )
    # -----------------------------------

    print("\n--- æ­¥é©Ÿ 3b: é–‹å§‹è¶…åƒæ•¸èª¿æ ¡ (åˆ†é¡æ¨¡å‹ï¼Œé€™æœƒèŠ±è²» 5-15+ åˆ†é˜...) ---")
    
    random_search.fit(X_train, y_train)

    print("\n--- èª¿æ ¡å®Œæˆ! ---")
    print(f"æœ€ä½³äº¤å‰é©—è­‰ (CV) æº–ç¢ºç‡: {random_search.best_score_:.2%}")
    print("æ‰¾åˆ°çš„æœ€ä½³åƒæ•¸çµ„åˆ:")
    print(random_search.best_params_)

    # ç²å–ã€Œæœ€ä½³åˆ†é¡å™¨ã€
    xgb_clf = random_search.best_estimator_

    print("\n--- æ­¥é©Ÿ 3c: ä½¿ç”¨ã€Œæœ€ä½³æ¨¡å‹ã€è©•ä¼°æ¸¬è©¦é›† ---")
    
    # --- ä¿®æ”¹: è©•ä¼°åˆ†é¡çµæœ ---
    y_pred = xgb_clf.predict(X_test)
    
    accuracy = accuracy_score(y_test, y_pred)
    print(f"\næ¨¡å‹åœ¨ã€Œæ¸¬è©¦é›†ã€ä¸Šçš„æº–ç¢ºç‡ (Accuracy): {accuracy:.2%}")
    print("\n--- è©³ç´°åˆ†é¡å ±å‘Š (Classification Report) ---")
    # é€™æœƒé¡¯ç¤º '0' (è·Œ) å’Œ '1' (æ¼²) çš„ç²¾ç¢ºåº¦ (Precision) å’Œå¬å›ç‡ (Recall)
    print(classification_report(y_test, y_pred, target_names=['è·Œ (0)', 'æ¼² (1)']))
    # ---------------------------

    # --- æ­¥é©Ÿ 4: é æ¸¬ 'çœŸæ­£' çš„æ˜å¤© (ä¸‹ä¸€æ ¹ K æ£’) ---
    print("\n--- æ­¥é©Ÿ 4: é æ¸¬ 'æ˜å¤©' çš„æ–¹å‘ ---")
    
    latest_features = df_features[features].iloc[-1:]
    print("ç”¨æ–¼é æ¸¬çš„ 'ä»Šå¤©' (æœ€æ–°) ç‰¹å¾µ:")
    print(latest_features)

    prediction_for_tomorrow = xgb_clf.predict(latest_features)
    prediction_proba = xgb_clf.predict_proba(latest_features)

    direction = "æ¼² (1)" if prediction_for_tomorrow[0] == 1 else "è·Œ (0)"
    confidence = prediction_proba[0][prediction_for_tomorrow[0]]

    print("\n=========================================================")
    print(f"ğŸ“ˆ é æ¸¬ 'æ˜å¤©' (ä¸‹ä¸€æ ¹ K ç·š) çš„æ–¹å‘: {direction}")
    print(f"   (æ¨¡å‹å°æ­¤é æ¸¬çš„ä¿¡å¿ƒæŒ‡æ•¸: {confidence:.2%})")
    print("=========================================================")
    
    # --- ä¿®æ”¹: è¿”å›åˆ†é¡å™¨å’Œæ¸¬è©¦è³‡æ–™ï¼Œç”¨æ–¼ç¹ªè£½æ··æ·†çŸ©é™£ ---
    return xgb_clf, X_test, y_test

# --- (èˆŠçš„ plot_backtest å·²åˆªé™¤) ---

# --- æ–°å¢: æ­¥é©Ÿ 5: ç¹ªè£½æ··æ·†çŸ©é™£ ---
def plot_confusion_matrix(classifier, X_test, y_test):
    """
    ç¹ªè£½æ··æ·†çŸ©é™£ (Confusion Matrix)
    """
    print("\n--- æ­¥é©Ÿ 5: æ­£åœ¨ç¹ªè£½æ··æ·†çŸ©é™£ (Confusion Matrix) ---")
    
    try:
        fig, ax = plt.subplots(figsize=(10, 7))
        ax.set_title('æ··æ·†çŸ©é™£ (Confusion Matrix)')
        
        # ç¹ªè£½
        ConfusionMatrixDisplay.from_estimator(
            classifier, 
            X_test, 
            y_test,
            ax=ax,
            cmap=plt.cm.Blues,
            display_labels=['å¯¦éš› è·Œ (0)', 'å¯¦éš› æ¼² (1)']
        )
        
        # èª¿æ•´æ¨™ç±¤
        ax.xaxis.set_ticklabels(['é æ¸¬ è·Œ (0)', 'é æ¸¬ æ¼² (1)'])
        ax.yaxis.set_ticklabels(['å¯¦éš› è·Œ (0)', 'å¯¦éš› æ¼² (1)'])
        
        print("æ­£åœ¨é¡¯ç¤ºåœ–è¡¨... (è«‹æŸ¥çœ‹å½ˆå‡ºè¦–çª—ï¼Œå¯èƒ½åœ¨ Python åœ–ç¤º)")
        print("åœ–è¡¨è§£é‡‹ï¼š")
        print(" [å·¦ä¸Š] é æ¸¬ è·Œï¼Œå¯¦éš› è·Œ (çŒœå°)")
        print(" [å³ä¸‹] é æ¸¬ æ¼²ï¼Œå¯¦éš› æ¼² (çŒœå°)")
        print(" [å·¦ä¸‹] é æ¸¬ æ¼²ï¼Œå¯¦éš› è·Œ (çŒœéŒ¯)")
        print(" [å³ä¸Š] é æ¸¬ è·Œï¼Œå¯¦éš› æ¼² (çŒœéŒ¯)")
        
        plt.show()

    except Exception as e:
        print(f"ç¹ªè£½æ··æ·†çŸ©é™£æ™‚å‡ºéŒ¯: {e}")

# --- ä¸»åŸ·è¡Œæµç¨‹ (ä¿®æ”¹) ---
if __name__ == "__main__":
    
    # 1. ç²å–è³‡æ–™
    # (æˆ‘å€‘ç¹¼çºŒä½¿ç”¨ 5m ETH ä¾†æ¯”è¼ƒ)
    raw_df = fetch_data(symbol='ETH/USDT', timeframe='5m', total_limit=10000)
    
    # 2. ç‰¹å¾µå·¥ç¨‹
    df_with_features = create_features(raw_df)
    
    # 3. è¨“ç·´èˆ‡é æ¸¬ (åˆ†é¡)
    best_classifier, X_test_data, y_test_data = train_and_predict(df_with_features)
    
    # 4. ç¹ªè£½æ··æ·†çŸ©é™£
    if best_classifier:
        plot_confusion_matrix(best_classifier, X_test_data, y_test_data)