import ccxt
import pandas as pd
import talib
import xgboost as xgb
from sklearn.metrics import mean_squared_error
import numpy as np
import warnings
import matplotlib.pyplot as plt
import time

# --- æ–°å¢: åŒ¯å…¥èª¿æ ¡å·¥å…· ---
from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit
from scipy.stats import uniform, randint
# --------------------------

# å¿½ç•¥ pandas çš„æœªä¾†è­¦å‘Š
warnings.simplefilter(action='ignore', category=FutureWarning)

# --- æ­¥é©Ÿ 1: ä½¿ç”¨ CCXT ç²å–è³‡æ–™ ---
# (èˆ‡ä¸Šä¸€ç‰ˆç›¸åŒï¼Œä¿æŒä¸è®Š)
def fetch_data(symbol='BTC/USDT', timeframe='5m', total_limit=10000):
    """
    å¾å¹£å®‰ (Binance) ç²å–å¤§é‡ OHLCV è³‡æ–™ (ä½¿ç”¨è¿´åœˆ)ã€‚
    """
    print(f"--- æ­¥é©Ÿ 1: æ­£åœ¨å¾ Binance ç²å– {symbol} {timeframe} è³‡æ–™ (ç›®æ¨™ {total_limit} ç­†) ---")
    
    exchange = ccxt.binance({'rateLimit': 1200, 'enableRateLimit': True})
    
    try:
        timeframe_duration_ms = exchange.parse_timeframe(timeframe) * 1000
    except Exception as e:
        print(f"Timeframe æ ¼å¼éŒ¯èª¤: {e}ã€‚è«‹ä½¿ç”¨ 1m, 3m, 5m, 15m, 1h, 4h, 1d...")
        return None
        
    limit_per_request = 1000
    all_ohlcv = []
    total_duration_ms = total_limit * timeframe_duration_ms
    since_timestamp = exchange.milliseconds() - total_duration_ms
    
    print(f"å°‡å¾ {pd.to_datetime(since_timestamp, unit='ms')} (å¤§ç´„) é–‹å§‹ç²å–è³‡æ–™...")

    while True:
        try:
            ohlcv = exchange.fetch_ohlcv(symbol, timeframe, since=since_timestamp, limit=limit_per_request)
            
            if not ohlcv:
                print("ç²å–å®Œæˆ (å·²é”æœ€æ–°è³‡æ–™)ã€‚")
                break
                
            all_ohlcv.extend(ohlcv)
            last_timestamp = ohlcv[-1][0]
            since_timestamp = last_timestamp + timeframe_duration_ms
            
            print(f"å·²ç²å– {len(all_ohlcv)} ç­†è³‡æ–™...")

        except ccxt.NetworkError as e:
            print(f"ç¶²è·¯éŒ¯èª¤: {e}ï¼Œ5 ç§’å¾Œé‡è©¦...")
            time.sleep(5)
        except Exception as e:
            print(f"ç²å–è³‡æ–™æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}")
            return None

    print(f"--- è³‡æ–™ç²å–å®Œç•¢ï¼Œç¸½å…± {len(all_ohlcv)} ç­† ---")

    if not all_ohlcv:
        print("æœ€çµ‚æœªç²å–åˆ°ä»»ä½•è³‡æ–™ã€‚")
        return None
        
    df = pd.DataFrame(all_ohlcv, columns=[
        'timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'
    ])
    df = df.drop_duplicates(subset=['timestamp'])
    
    if len(df) > total_limit:
        print(f"è³‡æ–™é‡éå¤š ({len(df)})ï¼Œå°‡è£å‰ªç‚ºæœ€æ–°çš„ {total_limit} ç­†ã€‚")
        df = df.tail(total_limit)
    elif len(df) < total_limit:
        print(f"è­¦å‘Šï¼šäº¤æ˜“æ‰€æä¾›çš„è³‡æ–™ä¸è¶³ {total_limit} ç­†ï¼Œåƒ…æœ‰ {len(df)} ç­†ã€‚")
        
    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
    df.set_index('timestamp', inplace=True)
    
    for col in ['Open', 'High', 'Low', 'Close', 'Volume']:
        df[col] = pd.to_numeric(df[col], errors='coerce')
        
    print("DataFrame è™•ç†å®Œæˆã€‚")
    return df

# --- æ­¥é©Ÿ 2: ä½¿ç”¨ TA-Lib é€²è¡Œç‰¹å¾µå·¥ç¨‹ ---
# (ä¸ä¸Šä¸€ç‰ˆç›¸åŒï¼Œä¿æŒä¸å˜)
def create_features(df):
    """
    è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ä½œç‚ºç‰¹å¾µã€‚
    """
    if df is None:
        return None
        
    print("\n--- æ­¥é©Ÿ 2: æ­£åœ¨è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ (ç‰¹å¾µå·¥ç¨‹) ---")
    
    close_prices = df['Close'].values.astype(float)
    high_prices = df['High'].values.astype(float)
    low_prices = df['Low'].values.astype(float)
    volume = df['Volume'].values.astype(float)

    try:
        df['RSI'] = talib.RSI(close_prices, timeperiod=14)
        df['WMA_close_2'] = talib.WMA(close_prices, timeperiod=2)
        df['WMA_high_2'] = talib.WMA(high_prices, timeperiod=2)
        df['WMA_low_2'] = talib.WMA(low_prices, timeperiod=2)
        
        macd, macdsignal, _ = talib.MACD(close_prices, 
                                         fastperiod=6, 
                                         slowperiod=13, 
                                         signalperiod=9)
        df['MACD'] = macd
        df['MACD_signal'] = macdsignal

        df['ADX'] = talib.ADX(df['High'], df['Low'], df['Close'])
        df['ADX_hist'] = talib.PLUS_DI(df['High'], df['Low'], df['Close']) - talib.MINUS_DI(df['High'], df['Low'], df['Close'])
        
        df['OBV'] = talib.OBV(close_prices, volume)

        upperband, middleband, lowerband = talib.BBANDS(close_prices, 
                                                        timeperiod=2, 
                                                        nbdevup=2, 
                                                        nbdevdn=2, 
                                                        matype=0)
        
        df['BB_Width'] = (upperband - lowerband) / (middleband + 1e-10)
        df['BB_Percent'] = (close_prices - lowerband) / (upperband - lowerband + 1e-10)

        original_len = len(df)
        df_features = df.dropna() 
        print(f"å·²å»é™¤ {original_len - len(df_features)} ç­†èˆŠè³‡æ–™ (å› è¨ˆç®—æŒ‡æ¨™ç”¢ç”Ÿ NaN)ã€‚")
        
        return df_features

    except Exception as e:
        print(f"è¨ˆç®—ç‰¹å¾µæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

# --- æ­¥é©Ÿ 3 & 4: (***é‡å¤§æ›´æ–°: åŠ å…¥è¶…åƒæ•¸èª¿æ ¡***) ---

def train_and_predict(df_features):
    """
    æº–å‚™è³‡æ–™ã€è‡ªå‹•èª¿æ ¡ä¸¦è¨“ç·´ XGBoost æ¨¡å‹ã€‚
    """
    if df_features is None or df_features.empty:
        print("æ²’æœ‰è¶³å¤ çš„ç‰¹å¾µè³‡æ–™é€²è¡Œè¨“ç·´ã€‚")
        return None, None

    print("\n--- æ­¥é©Ÿ 3: æº–å‚™è³‡æ–™ ---")

    features = [
        'RSI',
        'WMA_close_2', 'WMA_high_2', 'WMA_low_2',
        'MACD', 'MACD_signal', 'OBV',
        'ADX', 'ADX_hist',
        'Volume',
        'BB_Width',
        'BB_Percent'
    ]
    
    df_model = df_features.copy()
    df_model['target'] = df_model['Close'].shift(-1)
    df_model = df_model.dropna()

    X = df_model[features]
    y = df_model['target']

    test_size = 0.2 
    split_index = int(len(X) * (1 - test_size))

    X_train, X_test = X[:split_index], X[split_index:]
    y_train, y_test = y[:split_index], y[split_index:]

    print(f"è¨“ç·´é›†ç­†æ•¸: {len(X_train)}, æ¸¬è©¦é›†ç­†æ•¸: {len(X_test)}")

    # --- æ­¥é©Ÿ 3a: è¶…åƒæ•¸èª¿æ ¡è¨­å®š ---
    
    # 1. å®šç¾©è¦æœç´¢çš„åƒæ•¸ç¯„åœ
    # (æˆ‘å€‘å°‡ n_estimators ä¹ŸåŠ å…¥æœç´¢ï¼Œå› æ­¤ç§»é™¤ early_stopping)
    param_dist = {
        'n_estimators': randint(500, 1500),      # æ¨¹çš„æ•¸é‡
        'learning_rate': uniform(0.01, 0.05),  # å­¸ç¿’ç‡ (0.01 ~ 0.06)
        'max_depth': randint(3, 8),            # æ¨¹çš„æ·±åº¦
        'subsample': uniform(0.7, 0.3),        # è¨“ç·´æ¨£æœ¬æ¯”ä¾‹ (0.7 ~ 1.0)
        'colsample_bytree': uniform(0.7, 0.3)  # ç‰¹å¾µæ¯”ä¾‹ (0.7 ~ 1.0)
    }

    # 2. åŸºæœ¬æ¨¡å‹
    xgb_reg_base = xgb.XGBRegressor(
        objective='reg:squarederror',
        n_jobs=-1,
        random_state=42
    )

    # 3. å°ˆç‚ºæ™‚é–“åºåˆ—è¨­è¨ˆçš„äº¤å‰é©—è­‰ (éå¸¸é‡è¦!)
    tscv = TimeSeriesSplit(n_splits=3)

    # 4. éš¨æ©Ÿæœç´¢ç‰©ä»¶
    # n_iter=25: é›»è…¦æœƒéš¨æ©Ÿå˜—è©¦ 25 ç¨®çµ„åˆ
    # cv=tscv: ä½¿ç”¨æ™‚é–“åºåˆ—äº¤å‰é©—è­‰
    # scoring='neg_root_mean_squared_error': æˆ‘å€‘çš„è©•åˆ†æ¨™æº– (RMSE)
    random_search = RandomizedSearchCV(
        estimator=xgb_reg_base,
        param_distributions=param_dist,
        n_iter=25,  # å˜—è©¦ 25 ç¨®çµ„åˆ (æ‚¨å¯ä»¥å¢åŠ æ­¤æ•¸å­—ä»¥ç²å¾—æ›´å¥½ä½†æ›´æ…¢çš„çµæœ)
        cv=tscv,
        scoring='neg_root_mean_squared_error', # è² çš„ RMSE (å› ç‚º scikit-learn é è¨­æ˜¯è¶Šå¤§è¶Šå¥½)
        n_jobs=-1,  # ä½¿ç”¨æ‰€æœ‰ CPU æ ¸å¿ƒ
        verbose=2,  # é¡¯ç¤ºé€²åº¦
        random_state=42
    )

    print("\n--- æ­¥é©Ÿ 3b: é–‹å§‹è¶…åƒæ•¸èª¿æ ¡ (é€™æœƒèŠ±è²» 5-15+ åˆ†é˜...) ---")
    
    # *** åŸ·è¡Œæœç´¢ ***
    random_search.fit(X_train, y_train)

    print("\n--- èª¿æ ¡å®Œæˆ! ---")
    print(f"æœ€ä½³äº¤å‰é©—è­‰ (CV) RMSE: {-random_search.best_score_:.2f}")
    print("æ‰¾åˆ°çš„æœ€ä½³åƒæ•¸çµ„åˆ:")
    print(random_search.best_params_)

    # 5. ç²å–ã€Œæœ€ä½³æ¨¡å‹ã€
    # random_search æœƒè‡ªå‹•ç”¨æœ€ä½³åƒæ•¸é‡æ–°è¨“ç·´æ•´å€‹ X_train
    xgb_reg = random_search.best_estimator_

    # --- (èˆŠçš„ fit å€å¡Šå·²è¢« random_search.fit å–ä»£) ---

    print("\n--- æ­¥é©Ÿ 3c: ä½¿ç”¨ã€Œæœ€ä½³æ¨¡å‹ã€è©•ä¼°æ¸¬è©¦é›† ---")
    
    # --- è©•ä¼°æ¨¡å‹ ---
    y_pred = xgb_reg.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    print(f"æ¨¡å‹åœ¨ã€Œæ¸¬è©¦é›†ã€ä¸Šçš„ RMSE: {rmse:.2f} (é æ¸¬å¹³å‡èª¤å·®)")

    y_test_data = y_test
    y_pred_data = pd.Series(y_pred, index=y_test.index, name="Predicted")

    # --- æ­¥é©Ÿ 4: é æ¸¬ 'çœŸæ­£' çš„æ˜å¤© ---
    print("\n--- æ­¥é©Ÿ 4: é æ¸¬ 'æ˜å¤©' çš„åƒ¹æ ¼ ---")
    
    latest_features = df_features[features].iloc[-1:]
    print("ç”¨æ–¼é æ¸¬çš„ 'ä»Šå¤©' (æœ€æ–°) ç‰¹å¾µ:")
    print(latest_features)

    prediction_for_tomorrow = xgb_reg.predict(latest_features)

    print("\n=========================================================")
    print(f"ğŸ“ˆ é æ¸¬ 'æ˜å¤©' (ä¸‹ä¸€æ ¹ K ç·š) çš„ BTCUSDT æ”¶ç›¤åƒ¹: ${prediction_for_tomorrow[0]:.2f}")
    print(f"(åŸºæ–¼ 'ä»Šå¤©' çš„æ”¶ç›¤åƒ¹: ${df_features['Close'].iloc[-1]:.2f})")
    print("=========================================================")
    
    return y_test_data, y_pred_data

# --- æ­¥é©Ÿ 5: ç¹ªè£½å›æ¸¬åœ–è¡¨ ---
# (èˆ‡ä¸Šä¸€ç‰ˆç›¸åŒï¼Œä¿æŒä¸è®Š)
def plot_backtest(actual, predicted):
    """
    ä½¿ç”¨ matplotlib ç¹ªè£½çœŸå¯¦åƒ¹æ ¼èˆ‡é æ¸¬åƒ¹æ ¼ã€‚
    """
    if actual is None or predicted is None:
        print("\næ²’æœ‰å›æ¸¬è³‡æ–™å¯ä¾›ç¹ªåœ– (æ¸¬è©¦é›†å¯èƒ½ç‚ºç©º)ã€‚")
        return

    print("\n--- æ­¥é©Ÿ 5: æ­£åœ¨ç¹ªè£½å›æ¸¬çµæœ ---")
    
    plt.figure(figsize=(15, 7))
    
    plt.plot(actual.index, actual, label='Actual Price (çœŸå¯¦åƒ¹æ ¼)', color='blue', alpha=0.8)
    plt.plot(predicted.index, predicted, label='Predicted Price (é æ¸¬åƒ¹æ ¼)', color='red', linestyle='--', alpha=0.9)
    
    plt.title('XGBoost Backtest on BTCUSDT (æ¸¬è©¦é›†å›æ¸¬)')
    plt.xlabel('Date (æ—¥æœŸ)')
    plt.ylabel('Price (USDT)')
    plt.legend()
    plt.grid(True)
    
    print("æ­£åœ¨é¡¯ç¤ºåœ–è¡¨... (è«‹æŸ¥çœ‹å½ˆå‡ºè¦–çª—ï¼Œå¯èƒ½åœ¨ Python åœ–ç¤º)")
    plt.show()

# --- ä¸»åŸ·è¡Œæµç¨‹ ---
if __name__ == "__main__":
    
    # 1. ç²å–è³‡æ–™
    # (æˆ‘å€‘ç¹¼çºŒä½¿ç”¨ 5m ETH ä¾†æ¯”è¼ƒ)
    raw_df = fetch_data(symbol='ETH/USDT', timeframe='5m', total_limit=10000)
    
    # 2. ç‰¹å¾µå·¥ç¨‹
    df_with_features = create_features(raw_df)
    
    # 3. è¨“ç·´èˆ‡é æ¸¬ (åŒ…å«è‡ªå‹•èª¿æ ¡)
    actual_prices, predicted_prices = train_and_predict(df_with_features)
    
    # 4. ç¹ªè£½å›æ¸¬åœ–è¡¨
    plot_backtest(actual_prices, predicted_prices)