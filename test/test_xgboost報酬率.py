import ccxt
import pandas as pd
import talib
import xgboost as xgb
import lightgbm as lgb
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score
import numpy as np
import warnings
import matplotlib.pyplot as plt
import time  # --- æ–°å¢: è™•ç†ç¶²è·¯å»¶é² ---
import os  # --- æ–°å¢: ç”¨æ–¼æª¢æŸ¥å’Œè®€å¯« CSV ---

# å¿½ç•¥ pandas çš„æœªä¾†è­¦å‘Š
warnings.simplefilter(action='ignore', category=FutureWarning)

# --- æ­¥é©Ÿ 1: ä½¿ç”¨ CCXT ç²å–è³‡æ–™ (***é‡å¤§æ›´æ–°***) ---

def fetch_data(symbol='BTC/USDT', timeframe='5m', total_limit=10000):
    """
    å¾å¹£å®‰ (Binance) ç²å–å¤§é‡ OHLCV è³‡æ–™ (ä½¿ç”¨è¿´åœˆ)ã€‚
    """
    print(f"--- æ­¥é©Ÿ 1: æ­£åœ¨å¾ Binance ç²å– {symbol} {timeframe} è³‡æ–™ (ç›®æ¨™ {total_limit} ç­†) ---")
    
    # 1. åˆå§‹åŒ–äº¤æ˜“æ‰€
    exchange = ccxt.binance({'rateLimit': 1200, 'enableRateLimit': True})
    
    # 2. è¨ˆç®—æ™‚é–“
    try:
        # å°‡ '5m', '1h' ç­‰è½‰æ›ç‚ºæ¯«ç§’
        timeframe_duration_ms = exchange.parse_timeframe(timeframe) * 1000
    except Exception as e:
        print(f"Timeframe æ ¼å¼éŒ¯èª¤: {e}ã€‚è«‹ä½¿ç”¨ 1m, 3m, 5m, 15m, 1h, 4h, 1d...")
        return None
        
    limit_per_request = 1000  # å¹£å®‰ API æ¯æ¬¡è«‹æ±‚çš„ä¸Šé™
    all_ohlcv = []

    # 3. è¨ˆç®—èµ·å§‹æ™‚é–“ (å¾å¤šä¹…ä»¥å‰é–‹å§‹æŠ“)
    # ç¸½ç­†æ•¸ * æ¯ç­† K æ£’çš„æ™‚é–“ = ç¸½æ™‚é•·
    total_duration_ms = total_limit * timeframe_duration_ms
    since_timestamp = exchange.milliseconds() - total_duration_ms
    
    print(f"å°‡å¾ {pd.to_datetime(since_timestamp, unit='ms')} (å¤§ç´„) é–‹å§‹ç²å–è³‡æ–™...")

    # 4. è¿´åœˆç²å–è³‡æ–™ (å‘å‰ç²å–ï¼Œç›´åˆ°ã€Œç¾åœ¨ã€)
    while True:
        try:
            # ç²å– K ç·š (å¾ 'since_timestamp' é–‹å§‹)
            ohlcv = exchange.fetch_ohlcv(symbol, timeframe, since=since_timestamp, limit=limit_per_request)
            
            if not ohlcv:
                # æ²’æœ‰æ›´å¤šè³‡æ–™äº† (å·²æŠ“åˆ°æœ€æ–°)
                print("ç²å–å®Œæˆ (å·²é”æœ€æ–°è³‡æ–™)ã€‚")
                break
                
            all_ohlcv.extend(ohlcv)
            
            # æ›´æ–°ä¸‹ä¸€æ¬¡è¿´åœˆçš„ 'since' (å¾æœ€å¾Œä¸€æ ¹ K æ£’çš„æ™‚é–“æˆ³ + 1 é–‹å§‹)
            last_timestamp = ohlcv[-1][0]
            since_timestamp = last_timestamp + timeframe_duration_ms
            
            print(f"å·²ç²å– {len(all_ohlcv)} ç­†è³‡æ–™...")

        except ccxt.NetworkError as e:
            print(f"ç¶²è·¯éŒ¯èª¤: {e}ï¼Œ5 ç§’å¾Œé‡è©¦...")
            time.sleep(5) # ç­‰å¾… 5 ç§’
        except ccxt.ExchangeError as e:
            print(f"äº¤æ˜“æ‰€éŒ¯èª¤: {e}")
            return None
        except Exception as e:
            print(f"ç²å–è³‡æ–™æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}")
            return None

    print(f"--- è³‡æ–™ç²å–å®Œç•¢ï¼Œç¸½å…± {len(all_ohlcv)} ç­† ---")

    # 5. è½‰æ›ç‚º DataFrame
    if not all_ohlcv:
        print("æœ€çµ‚æœªç²å–åˆ°ä»»ä½•è³‡æ–™ã€‚")
        return None
        
    df = pd.DataFrame(all_ohlcv, columns=[
        'Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'
    ])
    
    # ç§»é™¤é‡è¤‡ (ä»¥é˜² API éŒ¯èª¤)
    df = df.drop_duplicates(subset=['Timestamp'])
    
    # 6. (é‡è¦!) è£å‰ªç‚ºæœ€æ–°çš„ N ç­†
    # å› ç‚ºæˆ‘å€‘æ˜¯å¾ "éå»" æŠ“åˆ° "ç¾åœ¨"ï¼Œè³‡æ–™é‡å¯èƒ½å¤šæ–¼ total_limit
    if len(df) > total_limit:
        print(f"è³‡æ–™é‡éå¤š ({len(df)})ï¼Œå°‡è£å‰ªç‚ºæœ€æ–°çš„ {total_limit} ç­†ã€‚")
        df = df.tail(total_limit)
    elif len(df) < total_limit:
        print(f"è­¦å‘Šï¼šäº¤æ˜“æ‰€æä¾›çš„è³‡æ–™ä¸è¶³ {total_limit} ç­†ï¼Œåƒ…æœ‰ {len(df)} ç­†ã€‚")
        
    df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='ms')
    df.set_index('Timestamp', inplace=True)
    
    for col in ['Open', 'High', 'Low', 'Close', 'Volume']:
        df[col] = pd.to_numeric(df[col], errors='coerce')
        
    print("DataFrame è™•ç†å®Œæˆã€‚")
    return df

# --- æ­¥é©Ÿ 2: ä½¿ç”¨ TA-Lib é€²è¡Œç‰¹å¾µå·¥ç¨‹ ---
# (èˆ‡æ‚¨ä¸Šä¸€ç‰ˆç›¸åŒï¼Œä¿æŒä¸è®Š)
def create_features(df):
    """
    è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ä½œç‚ºç‰¹å¾µã€‚
    """
    if df is None:
        return None
        
    print("\n--- æ­¥é©Ÿ 2: æ­£åœ¨è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ (ç‰¹å¾µå·¥ç¨‹) ---")
    
    close_prices = df['Close'].values.astype(float)
    high_prices = df['High'].values.astype(float)
    low_prices = df['Low'].values.astype(float)
    volume = df['Volume'].values.astype(float)
    close_sma = talib.SMA(close_prices, 3)
    df['Close_SMA'] = close_sma

    try:
        # æ‚¨çš„æŒ‡æ¨™ (WMA + å¿«é€Ÿ MACD + å¿«é€Ÿ BBANDS)
        ema = talib.EMA(close_prices, timeperiod=20)
        df['HOUR'] = df.index.hour
        df['D_OF_W'] = df.index.dayofweek
        df['MONTH'] = df.index.month
        df['EMA'] = ema
        df['CLOSE_EMA'] = (close_prices - ema) / ema
        df['ATR'] = talib.ATR(high_prices, low_prices, close_prices, timeperiod=14)
        df['RSI'] = talib.RSI(close_prices, timeperiod=14)
        df['MOM'] = talib.MOM(close_prices, timeperiod=10)
        df['ADX'] = talib.ADX(high_prices, low_prices, close_prices)
        df['ADX_hist'] = talib.PLUS_DI(high_prices, low_prices, close_prices) - talib.MINUS_DI(high_prices, low_prices, close_prices)
        df['ADX_hist_ema'] = talib.EMA(df['ADX_hist'], 10)
        df['WILLR'] = talib.WILLR(high_prices, low_prices, close_prices, timeperiod=20)

        df['KDJ_K'], df['KDJ_D'] = talib.STOCH(
                                    high_prices, 
                                    low_prices, 
                                    close_prices, 
                                    fastk_period=9,
                                    slowk_period=3,
                                    slowk_matype=0, # è¨­ç‚º 0 ä½¿ç”¨ SMA
                                    slowd_period=3,
                                    slowd_matype=0  # è¨­ç‚º 0 ä½¿ç”¨ SMA
                                    )
        df['KDJ_J'] = (3 * df['KDJ_K']) - (2 * df['KDJ_D'])
        
        df['MACD'], df['MACD_signal'], df['MACD_hist'] = talib.MACD(close_prices, 
                                                                    fastperiod=12, 
                                                                    slowperiod=26, 
                                                                    signalperiod=9)

        upperband, middleband, lowerband = talib.BBANDS(close_prices, 
                                                        timeperiod=20, 
                                                        nbdevup=2, 
                                                        nbdevdn=2, 
                                                        matype=0)
        
        df['BB_Width'] = (upperband - lowerband) / (middleband + 1e-10)
        df['BB_Percent'] = (close_prices - lowerband) / (upperband - lowerband + 1e-10)

        df['OBV'] = talib.OBV(close_prices, volume)
        df['VOLUME_CHANGE'] = df['Volume'].pct_change()
        df['VOLUME_CHANGE'].replace([np.inf, -np.inf], np.nan, inplace=True)

        df['return'] = (df['Close'].shift(-1) - close_prices) / close_prices
        df['return_lag_1'] = df['return'].shift(1)
        df['return_lag_2'] = df['return'].shift(2)
        df['return_lag_3'] = df['return'].shift(3)
        df['return_lag_4'] = df['return'].shift(4)
        df['return_lag_5'] = df['return'].shift(5)
        # --------------------------------

        original_len = len(df)
        df_features = df.dropna() 
        print(f"å·²å»é™¤ {original_len - len(df_features)} ç­†èˆŠè³‡æ–™ (å› è¨ˆç®—æŒ‡æ¨™ç”¢ç”Ÿ NaN)ã€‚")
        
        return df_features

    except Exception as e:
        print(f"è¨ˆç®—ç‰¹å¾µæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

# --- æ­¥é©Ÿ 3 & 4: è¨“ç·´ XGBoost ä¸¦é æ¸¬ ---
# (èˆ‡æ‚¨ä¸Šä¸€ç‰ˆç›¸åŒï¼Œä¿æŒä¸è®Š)
def train_and_predict(df_features):
    """
    æº–å‚™è³‡æ–™ã€è¨“ç·´ XGBoost æ¨¡å‹ä¸¦é æ¸¬ä¸‹ä¸€å¤©çš„åƒ¹æ ¼ã€‚
    """
    if df_features is None or df_features.empty:
        print("æ²’æœ‰è¶³å¤ çš„ç‰¹å¾µè³‡æ–™é€²è¡Œè¨“ç·´ã€‚")
        return None, None

    print("\n--- æ­¥é©Ÿ 3: æº–å‚™è³‡æ–™ä¸¦è¨“ç·´ XGBoost æ¨¡å‹ ---")

    features = [
        'HOUR',
        # 'D_OF_W',
        'MONTH',

        'EMA',
        'CLOSE_EMA',
        'ATR',
        'RSI',
        'MOM',
        'ADX',
        'ADX_hist',
        'ADX_hist_ema',
        'WILLR',
        'KDJ_K',
        'KDJ_D',
        'KDJ_J',

        'MACD', 'MACD_signal',
        'MACD_hist',
        
        'BB_Width',
        'BB_Percent',

        'OBV',
        'Volume',
        'VOLUME_CHANGE',

        # 'return',
        # 'return_lag_1',
        # 'return_lag_2',
        # 'return_lag_3',
        # 'return_lag_4',
        # 'return_lag_5',
    ]
    
    df_model = df_features.copy()
    df_model['target'] = df_model['Close'].shift(-1) / df_model['Close_SMA'] - 1
    df_model = df_model.dropna()

    X = df_model[features]
    y = df_model['target']

    # (é‡è¦) æ¸¬è©¦é›†æ¯”ä¾‹ä»ç„¶æ˜¯ 20%ã€‚ 
    # 10,000 ç­†è³‡æ–™ -> 8,000 ç­†è¨“ç·´ï¼Œ2,000 ç­†æ¸¬è©¦
    # æ‚¨çš„å›æ¸¬å°‡æœƒã€Œé•·å¾—å¤šã€ä¹Ÿã€Œå¯é å¾—å¤šã€
    test_size = 0.2 
    split_index = int(len(X) * (1 - test_size))

    X_train, X_test = X[:split_index], X[split_index:]
    y_train, y_test = y[:split_index], y[split_index:]

    print(f"è¨“ç·´é›†ç­†æ•¸: {len(X_train)}, æ¸¬è©¦é›†ç­†æ•¸: {len(X_test)}") # <--- é€™è£¡æœƒé¡¯ç¤ºæ–°æ•¸å­—

    xgb_reg = xgb.XGBRegressor(
        n_estimators=1000,
        learning_rate=0.01,
        # booster='gblinear',
        objective='reg:squarederror',
        n_jobs=-1,
        random_state=42,
        early_stopping_rounds=10,
        max_depth=3,
        reg_lambda=5,
    )

    y_test_data = None
    y_pred_data = None

    if not X_test.empty:
        xgb_reg.fit(
            X_train, 
            y_train,
            eval_set=[(X_train, y_train), (X_test, y_test)],
            verbose=False
        )
        xgb_reg.save_model(f"{symbol.replace('/', '_')}_{timeframe}.json")
        
        y_pred = xgb_reg.predict(X_test)

        actual_direction = np.sign(y_test)
        predicted_direction = np.sign(y_pred)
        actual_direction[actual_direction == 0] = 1
        predicted_direction[predicted_direction == 0] = 1
        accuracy = (actual_direction == predicted_direction).mean()
        print(f"æ–¹å‘æº–ç¢ºç‡: {accuracy * 100:.2f}%")

        market_up_percentage = (y_test > 0).mean()
        print(f"--- é—œéµé©—è­‰ ---")
        print(f"çœŸå¯¦å¸‚å ´(y_test)çš„ä¸Šæ¼²æ¯”ä¾‹: {market_up_percentage * 100:.2f}%")

        # rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        # print(f"æ¨¡å‹è©•ä¼° (RMSE): {rmse:.2f} (é æ¸¬å¹³å‡èª¤å·®)")

        # 1. å–å¾—ç‰¹å¾µåˆ—è¡¨ (X.columns å°±æ˜¯ features_list)
        features = X.columns 

        # 2. å–å¾—æ¨¡å‹è¨ˆç®—å‡ºçš„ã€Œé‡è¦æ€§ã€åˆ†æ•¸
        importances = xgb_reg.feature_importances_

        # 3. çµ„åˆä¸¦æ’åº
        feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})
        feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

        # 4. æ‰“å°çµæœ
        print("--- ç‰¹å¾µé‡è¦æ€§æ’è¡Œ ---")
        print(feature_importance_df)

        y_test_data = y_test
        y_pred_data = pd.Series(y_pred, index=y_test.index, name="Predicted")
        df_model['y_test'] = y_test_data
        df_model['y_pred'] = y_pred_data

    else:
        print("è³‡æ–™é‡ä¸è¶³ä»¥é€²è¡Œ early stoppingï¼Œç›´æ¥è¨“ç·´...")
        xgb_reg.fit(X_train, y_train)

    print("æ¨¡å‹è¨“ç·´å®Œæˆã€‚")

    # --- æ­¥é©Ÿ 4: é æ¸¬ 'çœŸæ­£' çš„æ˜å¤© ---
    # print("\n--- æ­¥é©Ÿ 4: é æ¸¬ 'æ˜å¤©' çš„åƒ¹æ ¼ ---")
    
    # latest_features = df_features[features].iloc[-1:]
    # print("ç”¨æ–¼é æ¸¬çš„ 'ä»Šå¤©' (æœ€æ–°) ç‰¹å¾µ:")
    # print(latest_features)

    # prediction_for_tomorrow = xgb_reg.predict(latest_features)

    # print("\n=========================================================")
    # print(f"ğŸ“ˆ é æ¸¬ 'æ˜å¤©' (ä¸‹ä¸€æ ¹ K ç·š) çš„ BTCUSDT æ”¶ç›¤åƒ¹: ${prediction_for_tomorrow[0]:.2f}")
    # print(f"(åŸºæ–¼ 'ä»Šå¤©' çš„æ”¶ç›¤åƒ¹: ${df_features['Close'].iloc[-1]:.2f})")
    # print("=========================================================")

    # mae = mean_absolute_error(y_test, y_pred)
    # mse = mean_squared_error(y_test, y_pred)
    # rmse = np.sqrt(mse)  # æˆ–è€… mean_squared_error(y_test, y_pred, squared=False)
    # r2 = r2_score(y_test, y_pred)

    # print(f"Mean Absolute Error (MAE): {mae}")
    # print(f"Root Mean Squared Error (RMSE): {rmse}")
    # print(f"R-squared (RÂ²): {r2}")
    
    return df_model

# --- æ­¥é©Ÿ 5: ç¹ªè£½å›æ¸¬åœ–è¡¨ ---
# (èˆ‡æ‚¨ä¸Šä¸€ç‰ˆç›¸åŒï¼Œä¿æŒä¸è®Š)
def plot_backtest(actual, predicted):
    """
    ä½¿ç”¨ matplotlib ç¹ªè£½çœŸå¯¦åƒ¹æ ¼èˆ‡é æ¸¬åƒ¹æ ¼ã€‚
    """
    if actual is None or predicted is None:
        print("\næ²’æœ‰å›æ¸¬è³‡æ–™å¯ä¾›ç¹ªåœ– (æ¸¬è©¦é›†å¯èƒ½ç‚ºç©º)ã€‚")
        return

    print("\n--- æ­¥é©Ÿ 5: æ­£åœ¨ç¹ªè£½å›æ¸¬çµæœ ---")
    
    plt.figure(figsize=(15, 7))
    
    plt.plot(actual.index, actual, label='Actual Price (çœŸå¯¦åƒ¹æ ¼)', color='blue', alpha=0.8)
    plt.plot(predicted.index, predicted, label='Predicted Price (é æ¸¬åƒ¹æ ¼)', color='red', linestyle='--', alpha=0.9)
    
    plt.title('XGBoost Backtest on BTCUSDT (æ¸¬è©¦é›†å›æ¸¬)')
    plt.xlabel('Date (æ—¥æœŸ)')
    plt.ylabel('Price (USDT)')
    plt.legend()
    plt.grid(True)
    
    print("æ­£åœ¨é¡¯ç¤ºåœ–è¡¨... (è«‹æŸ¥çœ‹å½ˆå‡ºè¦–çª—ï¼Œå¯èƒ½åœ¨ Python åœ–ç¤º)")
    plt.show()

# --- ä¸»åŸ·è¡Œæµç¨‹ (***é‡å¤§æ›´æ–°***) ---
if __name__ == "__main__":
    
    # å®šç¾© CSV æª”å (æ ¹æ“š symbol å’Œ timeframe å‹•æ…‹ç”Ÿæˆï¼Œé¿å…ç¡¬ç·¨ç¢¼)
    symbol = 'WLFI/USDT'
    timeframe = '15m'
    total_limit = 300000
    csv_path = f"{symbol.replace('/', '_')}_{timeframe}_data.csv"
    
    if os.path.exists(csv_path):
        print(f"--- æ‰¾åˆ° CSV æª”: {csv_path}ï¼Œæ­£åœ¨è®€å–... ---")
        raw_df = pd.read_csv(csv_path, index_col='Timestamp', parse_dates=True)
        for col in ['Open', 'High', 'Low', 'Close', 'Volume']:
            raw_df[col] = pd.to_numeric(raw_df[col], errors='coerce')
        print(f"å·²è®€å– {len(raw_df)} ç­†è³‡æ–™ã€‚")
    else:
        print(f"--- æœªæ‰¾åˆ° CSV æª”: {csv_path}ï¼Œé–‹å§‹æŠ“å–è³‡æ–™... ---")
        raw_df = fetch_data(symbol=symbol, timeframe=timeframe, total_limit=total_limit)
        if raw_df is not None:
            raw_df.to_csv(csv_path)
            print(f"è³‡æ–™å·²ä¿å­˜è‡³ {csv_path}ã€‚")
    
    # 2. ç‰¹å¾µå·¥ç¨‹
    df_with_features = create_features(raw_df)
    
    # 3. è¨“ç·´èˆ‡é æ¸¬ (ä¸¦æ¥æ”¶å›æ¸¬è³‡æ–™)
    df_result = train_and_predict(df_with_features)

    THRESHOLD = 0.0001
    FEE_RATE = 0.00055
    df_result['signal'] = 0
    df_result.loc[df_result['y_pred'] > THRESHOLD, 'signal'] = 1
    df_result.loc[df_result['y_pred'] < -THRESHOLD, 'signal'] = -1
    df_result['strategy_return'] = df_result['signal'].shift(1) * df_result['target']
    df_result['buy_and_hold_return'] = df_result['target']

    df_result['trades'] = df_result['signal'].diff().abs().fillna(0)
    df_result['transaction_costs'] = df_result['trades'] * FEE_RATE

    df_result['strategy_equity'] = df_result['strategy_return'] - df_result['transaction_costs']
    df_result['buy_and_hold_return'] = df_result['target']

    df_result['strategy_equity'] = df_result['strategy_return'].cumsum()
    df_result['buy_and_hold_equity'] = df_result['buy_and_hold_return'].cumsum()

    # --- 6. ç¹ªè£½çµæœ ---
    print("ç¹ªè£½å›æ¸¬çµæœ (å·²è¨ˆå…¥æ‰‹çºŒè²»)...")
    plt.figure(figsize=(14, 7))

    # ç•«å‡ºæ‚¨çš„ã€Œæ‰£è²»å¾Œã€ç­–ç•¥æ·¨å€¼
    df_result['strategy_equity'].plot(label='æ¨¡å‹ç­–ç•¥ (æ‰£è²»å¾Œ)', color='blue')

    # ç•«å‡ºã€Œè²·å…¥ä¸¦æŒæœ‰ã€(å¤§ç›¤) ä½œç‚ºå°æ¯”
    df_result['buy_and_hold_equity'].plot(label='è²·å…¥ä¸¦æŒæœ‰ (Buy & Hold)', color='gray', linestyle='--')

    plt.title('æ¨¡å‹ç­–ç•¥å›æ¸¬ (å·²è¨ˆå…¥æ‰‹çºŒè²» 0.04%)')
    plt.ylabel('ç´¯è¨ˆæ”¶ç›Šç‡ (Cumulative Returns)')
    plt.legend()
    plt.grid(True)
    plt.show()

    # --- 9. (å¯é¸) æ‰“å°ç¸½äº¤æ˜“æ¬¡æ•¸ ---
    print(f"--- ç­–ç•¥çµ±è¨ˆ ---")
    print(f"ç¸½äº¤æ˜“æ¬¡æ•¸ (Transactions): {df_result['trades'].sum()}")

    # 4. ç¹ªè£½å›æ¸¬åœ–è¡¨
    # plot_backtest(df_result['y_test'], df_result['y_pred'])