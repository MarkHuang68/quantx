# æª”æ¡ˆ: train_price_model.py (æœ€çµ‚å°ˆæ¥­ç‰ˆ)

import pandas as pd
import numpy as np
import argparse
import xgboost as xgb
import warnings
import os
import itertools
import json 
import math
from sklearn.metrics import mean_squared_error

# --- 1. å¼•ç”¨ã€Œè¨­å®šæª”ã€å’Œã€Œå…±ç”¨å·¥å…·ç®±ã€ ---
import config
from common_utils import fetch_data, create_features_price
from hyperparameter_search import SearchIterator

warnings.simplefilter(action='ignore', category=FutureWarning)

# --- æ‚¨çš„å°‹åƒç©ºé–“ (ä¿æŒä¸è®Š) ---
PRICE_SEARCH_SPACE = {
    'macd_fast': [6, 12],
    'macd_slow': [13, 26],
    'bbands': [2, 20, 6],
    'learning_rate': [0.01, 0.03, 0.05], 
    'max_depth': [2, 4, 6],
}
# --- æ‚¨çš„ XGBoost è¨“ç·´åŸºç¤åƒæ•¸ (ä¿æŒä¸è®Š) ---
XGB_BASE_PARAMS = {
    'n_estimators': 1000, 'objective': 'reg:squarederror',
    'n_jobs': -1, 'random_state': 42, 'early_stopping_rounds': 50
}


def train_xgb_regressor(df_features, features_list, params):
    """ (æ‚¨çš„è¨“ç·´å‡½æ•¸ï¼Œä¿æŒä¸è®Š) """
    if df_features is None: return None, np.inf

    # --- æ•¸æ“šæº–å‚™ (Target) ---
    df_model = df_features.copy()
    df_model['target'] = df_model['Close'].shift(-1)
    df_model = df_model.dropna()
    
    # 2. ç²å– X å’Œ Y
    X = df_model[features_list]
    y = df_model['target']
    
    # 3. åˆ†å‰²è¨“ç·´/æ¸¬è©¦é›†
    split_index = int(len(X) * 0.9) # 90% è¨“ç·´, 10% é©—è­‰ (ç”¨æ–¼ early stopping)
    X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]
    y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]

    # 4. è¨“ç·´é‚è¼¯
    xgb_reg = xgb.XGBRegressor(**params, **XGB_BASE_PARAMS)
    
    try:
        xgb_reg.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)
    except Exception as e:
        print(f"è¨“ç·´æ™‚å‡ºéŒ¯: {e}") # é¡¯ç¤ºéŒ¯èª¤
        return None, np.inf

    y_pred = xgb_reg.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    
    return xgb_reg, rmse

if __name__ == "__main__":
    
    # --- 3. å»ºç«‹ã€Œåƒæ•¸è§£æå™¨ã€ ---
    parser = argparse.ArgumentParser(description='è¨“ç·´ 5m XGBoost åƒ¹æ ¼æ¨¡å‹')
    
    parser.add_argument('-s', '--symbol', type=str, required=True, help='è¦è¨“ç·´çš„äº¤æ˜“å° (ä¾‹å¦‚: ETH/USDT æˆ– BTC/USDT)')
    parser.add_argument('-l', '--limit', type=int, default=config.PRICE_MODEL_TRAIN_LIMIT, help=f'K ç·šç­†æ•¸ (é è¨­: {config.PRICE_MODEL_TRAIN_LIMIT})')
    parser.add_argument('-v', '--version', type=str, default=config.PRICE_MODEL_VERSION, help=f'è¦è¨“ç·´çš„æ¨¡å‹ç‰ˆæœ¬ (é è¨­: {config.PRICE_MODEL_VERSION})')
    
    args = parser.parse_args()
    
    # --- 4. åŸ·è¡Œè¨“ç·´ (ç¶²æ ¼æœç´¢) ---
    print(f"--- é–‹å§‹åŸ·è¡Œ: {args.symbol} ({config.PRICE_MODEL_TIMEFRAME}), è³‡æ–™é‡={args.limit} ---")
    
    os.makedirs(config.MODEL_DIR, exist_ok=True)
    raw_df = fetch_data(symbol=args.symbol, timeframe=config.PRICE_MODEL_TIMEFRAME, total_limit=args.limit)
    
    # (*** é—œéµä¿®æ­£ï¼šä½¿ç”¨ raw_df çš„æœ€æ–°åƒ¹æ ¼ï¼Œè€Œä¸æ˜¯é‡æ–° fetch ***)
    current_price = raw_df['Close'].iloc[-1]
    
    # è¨­å®šåƒæ•¸æ ¼å¼, ç”Ÿæˆåƒæ•¸çµ„åˆ
    f_type = {
        'learning_rate': 'discrete', 
        'max_depth': 'discrete',
    }
    iterator = SearchIterator(PRICE_SEARCH_SPACE, search_type='grid', format_types=f_type)

    print(f"--- ç¸½å…±éœ€è¦åŸ·è¡Œ {iterator.get_total_runs()} æ¬¡è¨“ç·´ ---")
    
    best_rmse = np.inf
    best_model = None
    best_feature_params = None # <--- *** åªå„²å­˜ç‰¹å¾µé…ç½® ***
    
    # å®šç¾©å“ªäº›éµæ˜¯ç‰¹å¾µåƒæ•¸ (å¿…é ˆåŒ¹é… common_utils.py)
    FEATURE_KEYS = ['macd_fast', 'macd_slow', 'bbands']
    
    for i, params in enumerate(iterator):
        
        # 1a. åˆ†é›¢ç‰¹å¾µåƒæ•¸å’Œæ¨¡å‹åƒæ•¸
        feature_params = {k: params[k] for k in FEATURE_KEYS if k in params}
        xgb_params = {k: params[k] for k in params.keys() if k not in FEATURE_KEYS}

        # 1b. è¨ˆç®—ç‰¹å¾µ (å‚³å…¥ç‰¹å¾µåƒæ•¸)
        # (*** è­¦å‘Šï¼šæ‚¨çš„ common_utils.py å¿…é ˆæ›´æ–°ä»¥æ¥å— **feature_params ***)
        df_features, features_list = create_features_price(raw_df.copy(), **feature_params)
        if df_features is None or features_list is None: 
            print(f"Iter {i+1:02d}/{iterator.get_total_runs()}: ç‰¹å¾µè¨ˆç®—å¤±æ•—ï¼Œè·³éã€‚")
            continue
        
        # 1c. è¨“ç·´å’Œè©•ä¼°
        current_model, rmse = train_xgb_regressor(df_features, features_list, xgb_params)
        
        if math.isinf(rmse):
             print(f"Iter {i+1:02d}/{iterator.get_total_runs()}: è¨“ç·´å¤±æ•— (RMSE=inf)ã€‚ (Params: {feature_params}, LR={xgb_params.get('learning_rate')})")
             continue

        print(f"Iter {i+1:02d}/{iterator.get_total_runs()}: RMSE={rmse:.2f} (Params: {feature_params}, LR={xgb_params.get('learning_rate')})")
        
        if rmse < best_rmse:
            best_rmse = rmse
            best_model = current_model
            best_feature_params = feature_params 
    
    # --- 2. æœ€çµ‚æ¨¡å‹å„²å­˜å’Œè³ªé‡æ§åˆ¶ ---
    
    if not best_model:
        print("ğŸ›‘ è¨“ç·´å¤±æ•—ï¼šæœªèƒ½æ‰¾åˆ°æœ€ä½³æ¨¡å‹ã€‚")
        exit()
        
    # 2a. (*** è£œä¸Šçš„ã€Œçµ•å° RMSE æª¢æŸ¥ã€***)
    abs_max_rmse = current_price * config.ABS_MAX_RMSE_PCT
    
    if best_rmse > abs_max_rmse:
        print(f"\nâŒ è¨“ç·´å¤±æ•—ï¼æœ€ä½³ RMSE ({best_rmse:.2f}) è¶…éçµ•å°æ¥µé™ (${abs_max_rmse:.2f})ã€‚ä¸å„²å­˜æ¨¡å‹ã€‚")
        print("è«‹èª¿æ•´ PRICE_SEARCH_SPACE åƒæ•¸ä»¥ç²å¾—æ›´ç²¾ç¢ºçš„æ¨¡å‹ã€‚")
        exit()
    else:
        print(f"\nâœ… è³ªé‡é–€é€šéï¼æœ€ä½³ RMSE ({best_rmse:.2f}) å„ªæ–¼çµ•å°æ¥µé™ (${abs_max_rmse:.2f})ã€‚")

    # 2b. (*** è£œä¸Šçš„ã€Œç«¶çˆ­æ¨™æº–æª¢æŸ¥ã€ ***)
    # è¼‰å…¥ç¾è¡Œæ¨¡å‹å’Œé…ç½®
    current_model_path = config.get_price_model_path(args.symbol, args.version)
    current_config_path = current_model_path.replace('.json', '_feature_config.json')
    
    current_model = None
    historical_rmse = np.inf
    
    if os.path.exists(current_model_path) and os.path.exists(current_config_path):
        try:
            print(f"--- æ­£åœ¨è¼‰å…¥ç¾è¡Œæ¨¡å‹ ({args.version}) é€²è¡Œç«¶çˆ­æ¯”è¼ƒ... ---")
            current_model = xgb.Booster()
            current_model.load_model(current_model_path)
            
            with open(current_config_path, 'r') as f:
                current_feature_config = json.load(f)
            
            # (*** é—œéµï¼šåœ¨ã€Œç›¸åŒã€çš„ raw_df ä¸Šï¼Œç”¨ã€ŒèˆŠã€çš„ç‰¹å¾µåƒæ•¸å›æ¸¬ ***)
            print(f"æ­£åœ¨ä½¿ç”¨ç¾è¡Œæ¨¡å‹çš„ç‰¹å¾µåƒæ•¸ {current_feature_config} é€²è¡Œå›æ¸¬...")
            df_features_old, features_list_old = create_features_price(raw_df.copy(), **current_feature_config)
            
            # (æˆ‘å€‘éœ€è¦ä¸€å€‹ç¨ç«‹çš„è©•ä¼°å‡½æ•¸ï¼Œå› ç‚º train_xgb_regressor åŒ…å«äº†è¨“ç·´)
            df_model_old = df_features_old.copy()
            df_model_old['target'] = df_model_old['Close'].shift(-1)
            df_model_old = df_model_old.dropna()
            X_old = df_model_old[features_list_old]
            y_old = df_model_old['target']
            
            split_index_old = int(len(X_old) * 0.9)
            X_test_old = X_old.iloc[split_index_old:]
            y_test_old = y_old.iloc[split_index_old:]
            
            y_pred_old = current_model.predict(xgb.DMatrix(X_test_old))
            historical_rmse = np.sqrt(mean_squared_error(y_test_old, y_pred_old))
            
        except Exception as e:
            print(f"è­¦å‘Šï¼šè¼‰å…¥æˆ–è©•ä¼°ç¾è¡Œæ¨¡å‹å¤±æ•—ï¼š{e}")
            historical_rmse = np.inf
    else:
        print("--- æ‰¾ä¸åˆ°ç¾è¡Œæ¨¡å‹ï¼Œå°‡ç›´æ¥å„²å­˜æ–°æ¨¡å‹ã€‚ ---")

    # (*** è³ªé‡é–€ 2: ç«¶çˆ­æ¨™æº–æª¢æŸ¥ ***)
    if best_rmse >= historical_rmse:
        print(f"\nâŒ è¨“ç·´å¤±æ•—ï¼æ–°æ¨¡å‹ RMSE ({best_rmse:.2f}) ä¸¦æœªå„ªäºç¾è¡Œæ¨¡å‹ ({historical_rmse:.2f})ã€‚ä¸å„²å­˜æ¨¡å‹ã€‚")
        exit()
    else:
        print(f"\nâœ… è³ªé‡é–€ 2 (ç«¶çˆ­æ¨™æº–) é€šéï¼æ–°æ¨¡å‹ ({best_rmse:.2f}) æ“Šæ•— ç¾è¡Œæ¨¡å‹ ({historical_rmse:.2f})ã€‚")


    # 2c. å„²å­˜æ¨¡å‹å’Œæœ€ä½³åƒæ•¸ (*** æ ¸å¿ƒæ­¥é©Ÿ ***)
    model_filename = config.get_price_model_path(args.symbol, args.version)
    config_filename = config.get_price_model_path(args.symbol, args.version).replace('.json', '_feature_config.json')

    # å„²å­˜ XGBoost æ¨¡å‹
    if best_model:
        print(f"\n--- æ­£åœ¨å„²å­˜ã€Œåƒ¹æ ¼æ¨¡å‹ã€... ---")
        best_model.save_model(model_filename)
        print(f"æ¨¡å‹å„²å­˜å®Œç•¢ï¼({model_filename})")
    
    # (*** é—œéµä¿®æ­£ï¼šåªå„²å­˜ç‰¹å¾µåƒæ•¸ (best_feature_params) ***)
    if best_feature_params:
        with open(config_filename, 'w') as f:
            json.dump(best_feature_params, f, indent=4)
        print(f"âœ… æœ€ä½³ç‰¹å¾µé…ç½®å„²å­˜å®Œç•¢ï¼š{config_filename}")
